{"cells":[{"cell_type":"markdown","metadata":{},"source":["# 0. import"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-10T06:03:36.604791Z","iopub.status.busy":"2024-04-10T06:03:36.604452Z","iopub.status.idle":"2024-04-10T06:03:55.276444Z","shell.execute_reply":"2024-04-10T06:03:55.275651Z","shell.execute_reply.started":"2024-04-10T06:03:36.604763Z"},"id":"q5RKJsNVA6_3","trusted":true},"outputs":[],"source":["import warnings\n","warnings.filterwarnings(\"ignore\")\n","# pytorch 相關\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.utils.data import Dataset,DataLoader\n","from torch.utils.data import random_split\n","from torchvision import models\n","# 其他\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import cv2\n","from copy import copy\n","import os\n","import wandb\n","from wandb.keras import WandbCallback\n","import sklearn.metrics as metrics\n","import seaborn as sns\n","import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-10T06:04:09.952520Z","iopub.status.busy":"2024-04-10T06:04:09.951139Z","iopub.status.idle":"2024-04-10T06:04:09.979462Z","shell.execute_reply":"2024-04-10T06:04:09.978483Z","shell.execute_reply.started":"2024-04-10T06:04:09.952486Z"},"id":"gi8hFZEZGXD3","outputId":"772f63a2-657e-4f7b-a341-c9aa2e478742","trusted":true},"outputs":[],"source":["# check GPU\n","device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n","print('GPU state:', device)"]},{"cell_type":"markdown","metadata":{"id":"9FYgZegHI8Wc"},"source":["# 1. 設置超參數"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-10T06:04:11.879647Z","iopub.status.busy":"2024-04-10T06:04:11.878820Z","iopub.status.idle":"2024-04-10T06:04:11.884045Z","shell.execute_reply":"2024-04-10T06:04:11.883119Z","shell.execute_reply.started":"2024-04-10T06:04:11.879615Z"},"id":"79tbkTbxJCFo","trusted":true},"outputs":[],"source":["lr = 0.0001\n","batch_size = 128\n","epochs = 50\n","model_path = './m.pth'\n","train_path = '/kaggle/input/hw2-dataset/HW2_dataset/HW2_dataset/training'"]},{"cell_type":"markdown","metadata":{},"source":["# 2. Wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-10T03:13:19.701058Z","iopub.status.busy":"2024-04-10T03:13:19.700342Z","iopub.status.idle":"2024-04-10T03:13:24.139170Z","shell.execute_reply":"2024-04-10T03:13:24.137887Z","shell.execute_reply.started":"2024-04-10T03:13:19.701026Z"},"trusted":true},"outputs":[],"source":["# 紀錄數據\n","wandb.login(key = \"bf1bc673d9b5cb8bf02f1937561fb29fcb06a207\")\n","wandb.init(\n","    project = 'vgg16', \n","    name = 'batch_size: %d' % batch_size ,\n","    job_type = \"training\" , \n","    )\n","config = wandb.config\n","config.batch_size = batch_size"]},{"cell_type":"markdown","metadata":{"id":"3MXk8kKRJQMZ"},"source":["# 3. 數據預處理"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-10T06:04:19.499686Z","iopub.status.busy":"2024-04-10T06:04:19.498776Z","iopub.status.idle":"2024-04-10T06:04:19.507537Z","shell.execute_reply":"2024-04-10T06:04:19.506610Z","shell.execute_reply.started":"2024-04-10T06:04:19.499657Z"},"id":"wN-8fiyxJYhG","trusted":true},"outputs":[],"source":["# Normalize 和 totensor\n","train_transform = torchvision.transforms.Compose([\n","    torchvision.transforms.ToTensor(),\n","    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","\n","val_transform = torchvision.transforms.Compose([\n","    torchvision.transforms.ToTensor(),\n","    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","\n","test_transform = torchvision.transforms.Compose([\n","    torchvision.transforms.ToTensor(),\n","    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])"]},{"cell_type":"markdown","metadata":{"id":"D5jG_CUY7YYW"},"source":["# 切割train_validation & load_data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-10T06:04:22.336712Z","iopub.status.busy":"2024-04-10T06:04:22.336340Z","iopub.status.idle":"2024-04-10T06:04:25.422392Z","shell.execute_reply":"2024-04-10T06:04:25.421585Z","shell.execute_reply.started":"2024-04-10T06:04:22.336686Z"},"id":"2VVJy9uV7YYW","outputId":"55450264-7646-4002-cf9b-0fca5198bc01","trusted":true},"outputs":[],"source":["# 因需切割 train data 為 train 與 validation，所以需先讀入data並切割\n","# 讀資料\n","import glob\n","# 找出 train_path 底下所有檔案\n","train_list = glob.glob(os.path.join(train_path , '**/*.*') , recursive = True)\n","\n","# 切割\n","from sklearn.model_selection import train_test_split\n","train_list , val_list = train_test_split(train_list , test_size = 0.2 , random_state = 2)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-10T06:04:26.797183Z","iopub.status.busy":"2024-04-10T06:04:26.796474Z","iopub.status.idle":"2024-04-10T06:04:26.803367Z","shell.execute_reply":"2024-04-10T06:04:26.802317Z","shell.execute_reply.started":"2024-04-10T06:04:26.797154Z"},"trusted":true},"outputs":[],"source":["# 直接定義 class list 順序\n","cls_list = ['Jackson_Pollock', 'Alfred_Sisley', 'Jan_van_Eyck', 'Kazimir_Malevich', 'Sandro_Botticelli', 'Rembrandt', 'Vincent_van_Gogh', 'Raphael', 'Frida_Kahlo', 'Georges_Seurat', 'Edouard_Manet', 'Michelangelo', 'Salvador_Dali', 'Giotto_di_Bondone', 'Diego_Rivera', 'Peter_Paul_Rubens', 'William_Turner', 'Leonardo_da_Vinci', 'Piet_Mondrian', 'Vasiliy_Kandinskiy', 'Titian', 'Paul_Gauguin', 'Francisco_Goya', 'Edgar_Degas', 'Pablo_Picasso', 'Henri_Rousseau', 'Paul_Cezanne', 'Andy_Warhol', 'Mikhail_Vrubel', 'Diego_Velazquez', 'Hieronymus_Bosch', 'Eugene_Delacroix', 'Andrei_Rublev', 'Gustav_Klimt', 'Henri_Matisse', 'Gustave_Courbet', 'Caravaggio', 'Joan_Miro', 'Pierre-Auguste_Renoir', 'Rene_Magritte', 'Camille_Pissarro', 'Henri_de_Toulouse-Lautrec', 'El_Greco', 'Claude_Monet', 'Marc_Chagall', 'Paul_Klee', 'Edvard_Munch', 'Amedeo_Modigliani', 'Pieter_Bruegel']"]},{"cell_type":"markdown","metadata":{"id":"HnedtuA7Jgsw"},"source":["# 4. 載入 Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-10T06:04:29.259604Z","iopub.status.busy":"2024-04-10T06:04:29.258744Z","iopub.status.idle":"2024-04-10T06:04:29.268982Z","shell.execute_reply":"2024-04-10T06:04:29.268069Z","shell.execute_reply.started":"2024-04-10T06:04:29.259571Z"},"id":"3t56xSM_JuHJ","trusted":true},"outputs":[],"source":["class HW2(Dataset):\n","  def __init__(self, file_list , transform=None):\n","    self.file_list = file_list\n","    self.transform = transform\n","    # return 該路徑下之文件和文件夾列表\n","    # self.classes = os.listdir(train_path)\n","    self.classes = cls_list\n","    # dict : class_name對應index\n","    self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n","    self.images = self.load_images()\n","\n","  def get_classes(self):\n","    return self.classes\n","\n","  def load_images(self):\n","    images = []\n","    for img_path in self.file_list:\n","      # 從 path 中切割出 class 名\n","      cls_name = img_path.split(\"/\")[7]\n","      images.append((img_path, self.class_to_idx[cls_name]))\n","    return images\n","\n","  def __len__(self):\n","    return len(self.file_list)\n","\n","  def __getitem__(self, idx):\n","    img_path, label = self.images[idx]\n","    # 固定 image 的大小\n","    img = Image.open(img_path).resize([200 , 200]).convert('RGB')\n","    # 若有定義transform\n","    if self.transform:\n","        img = self.transform(img)\n","    return img, label"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-10T06:04:39.311828Z","iopub.status.busy":"2024-04-10T06:04:39.310918Z","iopub.status.idle":"2024-04-10T06:04:39.324533Z","shell.execute_reply":"2024-04-10T06:04:39.323385Z","shell.execute_reply.started":"2024-04-10T06:04:39.311793Z"},"id":"m8MypmsZs-Fl","trusted":true},"outputs":[],"source":["train_dataset = HW2(train_list , train_transform)\n","val_dataset = HW2(val_list , val_transform)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-10T06:04:42.060894Z","iopub.status.busy":"2024-04-10T06:04:42.060542Z","iopub.status.idle":"2024-04-10T06:04:42.065847Z","shell.execute_reply":"2024-04-10T06:04:42.064846Z","shell.execute_reply.started":"2024-04-10T06:04:42.060867Z"},"id":"yYjonvhnuvDB","outputId":"793eba83-0afb-42ec-b80f-b5676d72f193","trusted":true},"outputs":[],"source":["classes = train_dataset.get_classes()\n","print(classes)"]},{"cell_type":"markdown","metadata":{"id":"7T9isYs1tbdF"},"source":["# 5. 載入 Dataloader"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-10T06:04:44.005142Z","iopub.status.busy":"2024-04-10T06:04:44.004224Z","iopub.status.idle":"2024-04-10T06:04:44.010555Z","shell.execute_reply":"2024-04-10T06:04:44.009564Z","shell.execute_reply.started":"2024-04-10T06:04:44.005102Z"},"id":"S0wXF67LtFnR","trusted":true},"outputs":[],"source":["train_loader = DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True,num_workers=2)\n","val_loader = DataLoader(dataset=val_dataset,batch_size=batch_size,shuffle=False,num_workers=2)"]},{"cell_type":"markdown","metadata":{"id":"8g4wZ9DYwJPz"},"source":["# 6. 定義模型"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-09T14:57:53.131053Z","iopub.status.busy":"2024-04-09T14:57:53.130736Z","iopub.status.idle":"2024-04-09T14:57:55.168160Z","shell.execute_reply":"2024-04-09T14:57:55.166823Z","shell.execute_reply.started":"2024-04-09T14:57:53.131027Z"},"id":"xAXnPt13viea","outputId":"c1d2f575-f56a-469a-a3c6-13b224e3da86","trusted":true},"outputs":[],"source":["model = models.vgg19(weights='DEFAULT')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-09T14:57:55.169987Z","iopub.status.busy":"2024-04-09T14:57:55.169642Z","iopub.status.idle":"2024-04-09T14:57:55.338488Z","shell.execute_reply":"2024-04-09T14:57:55.337419Z","shell.execute_reply.started":"2024-04-09T14:57:55.169954Z"},"id":"GVWyT9tQw5u_","outputId":"bcc9060f-9cee-4b94-97a4-e3b0192fe7b1","trusted":true},"outputs":[],"source":["num_fcin = model.classifier[6].in_features\n","model.classifier[6] = nn.Linear(num_fcin, len(classes))\n","model.to(device)"]},{"cell_type":"markdown","metadata":{"id":"ZelcXPO0xxBR"},"source":["# 7. 定義 Cost function"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-09T14:57:55.342219Z","iopub.status.busy":"2024-04-09T14:57:55.341905Z","iopub.status.idle":"2024-04-09T14:57:55.375592Z","shell.execute_reply":"2024-04-09T14:57:55.374485Z","shell.execute_reply.started":"2024-04-09T14:57:55.342191Z"},"id":"Ws_XsALYxe9Z","trusted":true},"outputs":[],"source":["# 計算自定義 weight (先計算每個 class 數量) - 實作 penalized loss\n","class_num = []\n","for c in cls_list :\n","    p = os.path.join(train_path , c)\n","    num = len(os.listdir(p))\n","    class_num.append(num)\n","weights = []\n","for i in range(len(class_num)) : \n","    weights.append(sum(class_num) / class_num[i])\n","class_weights = torch.FloatTensor(weights).to(device)\n","\n","# 套入 loss 的 function 來改變計算權重\n","loss = nn.CrossEntropyLoss(weight = class_weights)\n","optimizer = optim.SGD(model.parameters(), lr, momentum=0.9,weight_decay=5e-4)\n","# optimizer = optim.Adam(model.parameters(), lr=1e-3, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)"]},{"cell_type":"markdown","metadata":{"id":"Y-Bjtme7yq8m"},"source":["# 8. 開始訓練"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-09T14:57:55.377916Z","iopub.status.busy":"2024-04-09T14:57:55.377545Z","iopub.status.idle":"2024-04-09T16:07:57.495880Z","shell.execute_reply":"2024-04-09T16:07:57.494667Z","shell.execute_reply.started":"2024-04-09T14:57:55.377883Z"},"id":"79Bm9zlSypm6","outputId":"4b012329-7843-4e9a-abfa-68a517faaed9","trusted":true},"outputs":[],"source":["# best model accurancy\n","best_acc = 0.0\n","train_loss = []\n","train_acc = []\n","val_loss = []\n","val_acc = []\n","macro_pre = []\n","macro_recall = []\n","micro_pre = []\n","micro_recall = []\n","\n","# 實作 learning rate 隨著 epoch 改變\n","def adjust_learning_rate(optimizer, epoch):\n","  if epoch <= 20:\n","    lr = 0.001\n","  elif epoch <= 40:\n","    lr = 0.001\n","  else:\n","    lr = 0.0001\n","  for param_group in optimizer.param_groups:\n","    param_group['lr'] = lr\n","\n","for epoch in range(epochs):\n","  # train\n","  train_epoch_loss = 0.0\n","\n","  train_class_correct = list(0. for i in range(len(classes)))\n","  train_class_total = list(0. for i in range(len(classes)))\n","\n","  # 每個 epoch 前都去看看要不要調 learning rate\n","  adjust_learning_rate(optimizer, epoch)\n","  \n","  # Evaluation Metrics 會用到\n","  total_label = np.array([])\n","  total_predicted = np.array([])\n","\n","  model.train()\n","  for i, data in enumerate(train_loader, 0):\n","    # enumerate 回傳的是 (下標 , data)\n","\n","    inputs, labels = data\n","    inputs, labels = inputs.to(device), labels.to(device)\n","\n","    optimizer.zero_grad()\n","    outputs = model(inputs)\n","\n","    # Compute Loss & Update Weight\n","    batch_loss = loss(outputs, labels)\n","    #　back propagation\n","    batch_loss.backward()\n","    # 更新\n","    optimizer.step()\n","\n","    train_epoch_loss += batch_loss.item()\n","\n","    # Compute train_class_correct of each batch\n","    _, predicted = torch.max(outputs, 1)\n","    # predicted 為預測出來之 label , 1 為 dim = 1 列出每行的最大值\n","    batch_correct = (predicted == labels)\n","    # 回傳一個 tensor 用於計算正確幾個\n","    for j in range(len(labels)):\n","      label = labels[j]\n","      train_class_correct[label] += batch_correct[j].item()\n","      train_class_total[label] += 1\n","\n","  # Compute Loss & Acc\n","  train_epoch_loss = train_epoch_loss / len(train_loader)\n","  train_epoch_accuracy = sum(train_class_correct) / sum(train_class_total) * 100\n","\n","  train_loss.append(train_epoch_loss)\n","  train_acc.append(train_epoch_accuracy)\n","\n","  print()\n","  print('[Epoch:%2d]' % (epoch + 1))\n","  print('Train Accuracy of All : %.3f %%' % (train_epoch_accuracy))\n","  print('Train Loss of All : %.3f ' % (train_epoch_loss))\n","  print(\"----------------------------------------\")\n","\n","    \n","  # Validation class correct & class total --------------------------------------------------------------\n","  model.eval()\n","  val_epoch_loss = 0.0\n","  val_class_correct = list(0. for i in range(len(classes)))\n","  val_class_total = list(0. for i in range(len(classes)))\n","\n","  # Validation every epoch\n","  with torch.no_grad():\n","    for data in val_loader :\n","      images, labels = data\n","      images, labels = images.to(device), labels.to(device)\n","      outputs = model(images)\n","\n","      # 1. Compute val_batch_loss\n","      batch_loss = loss(outputs, labels)\n","      val_epoch_loss += batch_loss.item()\n","\n","      # 2. Compute val_class_correct of each batch\n","      _, predicted = torch.max(outputs, 1)\n","      batch_correct = (predicted == labels)\n","      for j in range(len(labels)):\n","        label = labels[j]\n","        val_class_correct[label] += batch_correct[j].item()\n","        val_class_total[label] += 1\n","      \n","      # 整理所有結果\n","      total_label = np.append(total_label , labels.cpu().numpy())\n","      total_predicted = np.append(total_predicted , predicted.cpu().numpy())\n","\n","  # Evaluation Metrics\n","  val_epoch_accuracy = sum(val_class_correct) / sum(val_class_total) * 100\n","  val_epoch_loss = val_epoch_loss / len(val_loader)\n","  mac_epoch_pre = metrics.precision_score(total_label, total_predicted, average = 'macro') * 100\n","  mac_epoch_recall = metrics.recall_score(total_label, total_predicted, average = 'macro') * 100\n","  mic_epoch_pre = metrics.precision_score(total_label, total_predicted, average = 'micro') * 100\n","  mic_epoch_recall = metrics.recall_score(total_label, total_predicted, average = 'micro') * 100\n","\n","  val_loss.append(val_epoch_loss)\n","  val_acc.append(val_epoch_accuracy)\n","  macro_pre.append(mac_epoch_pre)\n","  macro_recall.append(mac_epoch_recall)\n","  micro_pre.append(mic_epoch_pre)\n","  micro_recall.append(mic_epoch_recall)\n","    \n","  wandb.log( {\"train_accuracy\" : train_epoch_accuracy , \"epoch\" : epoch} )\n","  wandb.log( {\"train_loss\" : train_epoch_loss , \"epoch\" : epoch} )\n","  wandb.log( {\"validation_accuracy\" : val_epoch_accuracy , \"epoch\" : epoch} )\n","  wandb.log( {\"validation_loss\" : val_epoch_loss , \"epoch\" : epoch} )\n","  wandb.log( {\"macro_precision\" : mac_epoch_pre , \"epoch\" : epoch} )\n","  wandb.log( {\"macro_recall\" : mac_epoch_recall , \"epoch\" : epoch} )\n","  wandb.log( {\"micro_precision\" : mic_epoch_pre , \"epoch\" : epoch} )\n","  wandb.log( {\"micro_recall\" : mic_epoch_recall , \"epoch\" : epoch} )\n","  \n","  print('Validation Accuracy of All : %.3f %%' % (val_epoch_accuracy))\n","  print('Validation Loss of All : %.3f ' % (val_epoch_loss))\n","  print('Validation Macro-averaged Precision of All : %.3f %%' % (mac_epoch_pre))\n","  print('Validation Macro-averaged Recall of All : %.3f %%' % (mac_epoch_recall))\n","  print('Validation Micro-averaged Precision of All : %.3f %%' % (mic_epoch_pre))\n","  print('Validation Micro-averaged Recall of All : %.3f %%' % (mic_epoch_recall))\n","  print(\"----------------------------------------\")\n","\n","  # Save best model\n","  if val_epoch_accuracy > best_acc:\n","    best_acc = val_epoch_accuracy\n","    torch.save(model.state_dict() , model_path)\n","print('Finished Training')\n","wandb.finish()"]},{"cell_type":"markdown","metadata":{},"source":["# 9. 測試"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-10T06:05:49.026612Z","iopub.status.busy":"2024-04-10T06:05:49.026081Z","iopub.status.idle":"2024-04-10T06:06:15.452534Z","shell.execute_reply":"2024-04-10T06:06:15.451598Z","shell.execute_reply.started":"2024-04-10T06:05:49.026567Z"},"trusted":true},"outputs":[],"source":["# 載入訓練好的 model\n","m = models.vgg19()\n","num_fcin = m.classifier[6].in_features\n","m.classifier[6] = nn.Linear(num_fcin, len(classes))\n","w = torch.load(\"/kaggle/input/mmmmmm/m (1).pth\")\n","m.load_state_dict(w)\n","m = m.cuda()\n","m.eval()\n","\n","class_to_index = {cls_name: i for i, cls_name in enumerate(cls_list)}\n","test_path = '/kaggle/input/hw2-dataset/HW2_dataset/HW2_dataset/testing'\n","test = pd.read_csv(\"/kaggle/input/test-csv/Homework2.csv\")\n","pre = []\n","\n","with torch.no_grad():\n","  for data in test[\"image\"] :\n","      # 找到該 image\n","      img_path = os.path.join(test_path , data)\n","      img = Image.open(img_path).resize([200 , 200]).convert('RGB')\n","      img = test_transform(img)\n","      images = img\n","      images = images.to(device)\n","      # reshape 成 Model 要的\n","      images = torch.reshape(images , (1 , 3 , 200 , 200))\n","      outputs = m(images)\n","\n","      _, predicted = torch.max(outputs, 1)\n","      p = predicted.data.cpu().numpy()[0]\n","      # 記錄起來該結果\n","      pre.append(p)\n","\n","# 寫入 dataframe 中\n","for i in range(len(pre)) :\n","    test[\"Painter\"][i] = cls_list[pre[i]]\n","\n","# 匯出\n","test.to_csv(\"result.csv\")\n","# 再手動將第一 column 刪除"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4685070,"sourceId":7963671,"sourceType":"datasetVersion"},{"datasetId":4685249,"sourceId":7963915,"sourceType":"datasetVersion"},{"datasetId":4767694,"sourceId":8078344,"sourceType":"datasetVersion"},{"datasetId":4767707,"sourceId":8078363,"sourceType":"datasetVersion"}],"dockerImageVersionId":30674,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
